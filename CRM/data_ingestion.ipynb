{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from pyspark.sql import DataFrame\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement 1: Ensuring Data Accuracy\n",
    "**Objective: Ensure that data across different files is accurate and correctly linked.**\n",
    "\n",
    "Description:\n",
    "\n",
    "1.\tLoad Data: Load data from all files into data frames using PySpark.\n",
    "2.\tInitial Validation: Check that data has been ingested correctly into data frames.\n",
    "3.\tVerify Data Accuracy:\n",
    "    -\tConfirm that Customer_ID in transactions.csv, interactions.csv, and customers.csv matches correctly.\n",
    "    -\tCheck that Product_ID in transactions.csv is valid according to products.csv.\n",
    "    -\tEnsure that Sales_Rep_ID in transactions.csv matches entries in sales_team.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/20 05:08:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "%run utilities/common_utility.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/20 05:08:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = initialize_spark_session(\"Interaction Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:08:36,201 - logger - INFO - \u001b[92mLogger initialized with dynamic path!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "log_file_path = 'logs/analysis.log'\n",
    "logger = initialize_logger(log_file_path)\n",
    "\n",
    "logger.info(\"Logger initialized with dynamic path!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:08:36,361 - logger - INFO - \u001b[92mLoaded Dataset/customers.csv successfully.\u001b[0m\n",
      "2024-09-20 05:08:36,465 - logger - INFO - \u001b[92mLoaded Dataset/products.csv successfully.\u001b[0m\n",
      "2024-09-20 05:08:36,557 - logger - INFO - \u001b[92mLoaded Dataset/transactions.csv successfully.\u001b[0m\n",
      "2024-09-20 05:08:36,657 - logger - INFO - \u001b[92mLoaded Dataset/interactions.csv successfully.\u001b[0m\n",
      "2024-09-20 05:08:36,754 - logger - INFO - \u001b[92mLoaded Dataset/sales_team.csv successfully.\u001b[0m\n",
      "2024-09-20 05:08:36,756 - logger - INFO - \u001b[92mCustomers DataFrame:\u001b[0m\n",
      "2024-09-20 05:08:36,797 - logger - INFO - \u001b[92mDisplayed first 5 records for Customers DataFrame.\u001b[0m\n",
      "2024-09-20 05:08:36,798 - logger - INFO - \u001b[92mProducts DataFrame:\u001b[0m\n",
      "2024-09-20 05:08:36,838 - logger - INFO - \u001b[92mDisplayed first 5 records for Products DataFrame.\u001b[0m\n",
      "2024-09-20 05:08:36,839 - logger - INFO - \u001b[92mTransactions DataFrame:\u001b[0m\n",
      "2024-09-20 05:08:36,885 - logger - INFO - \u001b[92mDisplayed first 5 records for Transactions DataFrame.\u001b[0m\n",
      "2024-09-20 05:08:36,887 - logger - INFO - \u001b[92mInteractions DataFrame:\u001b[0m\n",
      "2024-09-20 05:08:36,927 - logger - INFO - \u001b[92mDisplayed first 5 records for Interactions DataFrame.\u001b[0m\n",
      "2024-09-20 05:08:36,929 - logger - INFO - \u001b[92mSales_team DataFrame:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mCustomers DataFrame:\u001b[0m\n",
      "+------------------------------------+-----------------+----------------------+-------------+----------------+\n",
      "|Customer_ID                         |Name             |Email                 |Phone        |Country         |\n",
      "+------------------------------------+-----------------+----------------------+-------------+----------------+\n",
      "|a85e6a90-78d5-490c-a53f-c58b2e57c59b|Shannon Deleon   |NULL                  |5878628895   |Japan           |\n",
      "|babec972-ffb3-4c56-99c3-e8e3855adf0f|Christina Sanchez|craigprice@example.org|4832368495   |Haiti           |\n",
      "|d74c33bd-69d9-4718-9e00-d1895a41ddac|Thomas Brown     |vjohnson@example.org  |(276)903-7065|Pakistan        |\n",
      "|ff05ceba-f459-4714-a252-e03198d9934c|Lindsey Bradford |kathryn50@example.net |NULL         |Marshall Islands|\n",
      "|f20755f6-8481-4904-afe6-504451ceded5|John Boyer       |jennifer15@example.org|(749)644-5721|New Caledonia   |\n",
      "+------------------------------------+-----------------+----------------------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\u001b[92mProducts DataFrame:\u001b[0m\n",
      "+----------+--------------+-----------+------+\n",
      "|Product_ID|Product_Name  |Category   |Price |\n",
      "+----------+--------------+-----------+------+\n",
      "|1         |Sofa Set      |Home       |411.0 |\n",
      "|2         |Laptop        |Electronics|333.0 |\n",
      "|3         |Dining Table  |Home       |645.0 |\n",
      "|4         |Vacuum Cleaner|NULL       |290.0 |\n",
      "|5         |Mobile Phone  |Electronics|1738.0|\n",
      "+----------+--------------+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\u001b[92mTransactions DataFrame:\u001b[0m\n",
      "+------------------------------------+------------------------------------+----------+----------+------+------------------------------------+\n",
      "|Transaction_ID                      |Customer_ID                         |Product_ID|Date      |Amount|Sales_Rep_ID                        |\n",
      "+------------------------------------+------------------------------------+----------+----------+------+------------------------------------+\n",
      "|31190b6c-54cd-4cdb-a89e-7d8633b386df|d7522cab-f713-4c74-9d32-fadba3a20a85|48        |2024-04-01|234.0 |8aede4f3-bd43-45a7-9edc-5d69a2645fa1|\n",
      "|05d4bcca-dc8e-405c-81aa-d2bfc2acbc00|dae0689d-0c38-440c-b921-fe2413c3df3b|3         |2024-03-28|119.0 |c48b42a3-544b-4542-8528-4208e6f80b46|\n",
      "|9b6e01be-1814-41e0-bd7d-3ae2f845f5bf|075005e4-bb34-4965-bb28-fd100b10c45c|26        |2024-06-09|240.0 |d7558c8d-5355-48e7-8b88-30ab41ff2b8f|\n",
      "|46bd8f7c-20e0-405b-a1fe-b78e2b9a6813|ec910504-7738-463c-b269-1b1617b09ad1|37        |2024-03-24|451.0 |d0fa26a0-d161-4976-ae9a-9c5f74fc103c|\n",
      "|f02dded4-81bf-4310-8715-65e4fa9e1042|84441f52-77e5-450b-97d2-80f64c5c4fb4|4         |2024-05-29|78.0  |8aede4f3-bd43-45a7-9edc-5d69a2645fa1|\n",
      "+------------------------------------+------------------------------------+----------+----------+------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\u001b[92mInteractions DataFrame:\u001b[0m\n",
      "+------------------------------------+------------------------------------+----------------+----------------+--------------+\n",
      "|Interaction_ID                      |Customer_ID                         |Interaction_Date|Interaction_Type|Issue_Resolved|\n",
      "+------------------------------------+------------------------------------+----------------+----------------+--------------+\n",
      "|5a367006-c47a-4728-a042-c4c6ddd9ee3e|4166b61a-cb6d-4190-ac0b-df812c0308ff|2024-08-07      |NULL            |true          |\n",
      "|544d6348-cc9c-4c36-9fbe-eaf7e845e682|cc9a2115-b197-4a2b-9a6a-0fb2da5a0c73|2024-01-30      |Email           |true          |\n",
      "|b1739e10-0690-4ec6-9a6b-147127c0f388|1f22e566-13a0-4758-b42c-b0f6e997d46c|2024-06-27      |Chat            |true          |\n",
      "|3d9dcd53-7edd-4672-bfcf-a03b430b2935|dae0689d-0c38-440c-b921-fe2413c3df3b|2024-07-20      |Email           |false         |\n",
      "|2861521b-43ba-45d9-a0bd-9ee5c2e3edf4|c1e7a24a-0cc4-4a3e-8cf1-1e3487076ef4|2024-05-31      |Email           |false         |\n",
      "+------------------------------------+------------------------------------+----------------+----------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\u001b[92mSales_team DataFrame:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:08:36,976 - logger - INFO - \u001b[92mDisplayed first 5 records for Sales_team DataFrame.\u001b[0m\n",
      "2024-09-20 05:08:36,977 - logger - INFO - \u001b[92mVerifying Customer_ID matches between transactions.csv and customers.csv...\u001b[0m\n",
      "2024-09-20 05:08:36,980 - logger - INFO - \u001b[92mStarting validation of Customer_ID between transactions.csv and customers.csv.\u001b[0m\n",
      "2024-09-20 05:08:37,096 - logger - INFO - \u001b[92mNo missing Customer_IDs found between Customer_ID and Customer_ID.\u001b[0m\n",
      "2024-09-20 05:08:37,098 - logger - INFO - \u001b[92mVerifying Customer_ID matches between interactions.csv and customers.csv...\u001b[0m\n",
      "2024-09-20 05:08:37,098 - logger - INFO - \u001b[92mStarting validation of Customer_ID between interactions.csv and customers.csv.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------+-------------+------------+--------------+\n",
      "|Sales_Rep_ID                        |Name             |Region       |Sales_Target|Sales_Achieved|\n",
      "+------------------------------------+-----------------+-------------+------------+--------------+\n",
      "|0437b05a-9628-43f9-ac07-0b9a0dc96dcd|Brittany Taylor  |California   |41135       |14037.0       |\n",
      "|4daeb6af-d7e9-4f99-91b3-6c912f45b740|Mitchell Williams|New Hampshire|32996       |21461.0       |\n",
      "|f243144e-485f-4382-81ef-2a9a3c63f172|John Terry       |Kansas       |10385       |NULL          |\n",
      "|9c44ee81-8254-45e1-af23-a4608ceb126c|Carolyn Miller   |Arizona      |23754       |17149.0       |\n",
      "|3e97b5d8-933a-4860-bce7-2398af6c5613|Antonio Sparks   |Washington   |27101       |36413.0       |\n",
      "+------------------------------------+-----------------+-------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\u001b[92mVerifying Customer_ID matches between transactions.csv and customers.csv...\u001b[0m\n",
      "No missing Customer_IDs found.\n",
      "\u001b[92mVerifying Customer_ID matches between interactions.csv and customers.csv...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:08:37,219 - logger - INFO - \u001b[92mNo missing Customer_IDs found between Customer_ID and Customer_ID.\u001b[0m\n",
      "2024-09-20 05:08:37,220 - logger - INFO - \u001b[92mVerifying Product_ID matches between transactions.csv and products.csv...\u001b[0m\n",
      "2024-09-20 05:08:37,222 - logger - INFO - \u001b[92mStarting validation of Product_ID between transactions.csv and products.csv.\u001b[0m\n",
      "2024-09-20 05:08:37,344 - logger - INFO - \u001b[92mNo missing Product_IDs found between Product_ID and Product_ID.\u001b[0m\n",
      "2024-09-20 05:08:37,345 - logger - INFO - \u001b[92mVerifying Sales_Rep_ID matches between transactions.csv and sales_team.csv...\u001b[0m\n",
      "2024-09-20 05:08:37,346 - logger - INFO - \u001b[92mStarting validation of Sales_Rep_ID between transactions.csv and sales_team.csv.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing Customer_IDs found.\n",
      "\u001b[92mVerifying Product_ID matches between transactions.csv and products.csv...\u001b[0m\n",
      "No missing Product_IDs found.\n",
      "\u001b[92mVerifying Sales_Rep_ID matches between transactions.csv and sales_team.csv...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:08:37,475 - logger - INFO - \u001b[92mNo missing Sales_Rep_IDs found between Sales_Rep_ID and Sales_Rep_ID.\u001b[0m\n",
      "2024-09-20 05:08:37,476 - logger - INFO - \u001b[92mData validation completed successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing Sales_Rep_IDs found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_green(text: str):\n",
    "    \"\"\"\n",
    "    Print text in green to the console and log it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\033[92m{text}\\033[0m\")\n",
    "        logger.info(f\"{text}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to print text: {e}\")\n",
    "\n",
    "def validate_ids(df1: DataFrame, df2: DataFrame, df1_col: str, df2_col: str, id_name: str):\n",
    "    \"\"\"\n",
    "    Validate the presence of IDs from df1 in df2 and display any missing IDs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure columns exist in both DataFrames\n",
    "        if df1_col not in df1.columns or df2_col not in df2.columns:\n",
    "            raise ValueError(f\"Column '{df1_col}' or '{df2_col}' not found in the DataFrames.\")\n",
    "\n",
    "        # Perform the left anti join to find missing IDs\n",
    "        missing_ids = df1.join(df2, df1[df1_col] == df2[df2_col], \"left_anti\") \\\n",
    "                         .select(df1[df1_col].alias(f\"Missing_{id_name}\"))\n",
    "        \n",
    "        if missing_ids.count() > 0:\n",
    "            print_green(f\"{id_name}s missing in {df2_col.split('_')[0]}.csv from {df1_col.split('_')[0]}.csv:\")\n",
    "            missing_ids.show()\n",
    "            logger.info(f\"{id_name}s missing in {df2_col.split('_')[0]}.csv from {df1_col.split('_')[0]}.csv:\")\n",
    "        else:\n",
    "            print(f\"No missing {id_name}s found.\")\n",
    "            logger.info(f\"No missing {id_name}s found between {df1_col} and {df2_col}.\")\n",
    "\n",
    "    except AnalysisException as ae:\n",
    "        logger.error(f\"Error during DataFrame operation: {ae}\")\n",
    "    except ValueError as ve:\n",
    "        logger.error(f\"Validation error: {ve}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during validation: {e}\")\n",
    "\n",
    "def load_data_files(file_paths: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Load CSV files into Spark DataFrames, with error handling for missing files and invalid formats.\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    for name, file in file_paths.items():\n",
    "        try:\n",
    "            if not os.path.exists(file):\n",
    "                raise FileNotFoundError(f\"File '{file}' not found.\")\n",
    "            dfs[name] = spark.read.csv(file, header=True, inferSchema=True)\n",
    "            logger.info(f\"Loaded {file} successfully.\")\n",
    "        except FileNotFoundError as fnfe:\n",
    "            logger.error(fnfe)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "def display_dataframes(dfs: dict):\n",
    "    \"\"\"\n",
    "    Display the first 5 records for each DataFrame, with error handling.\n",
    "    \"\"\"\n",
    "    for name, df in dfs.items():\n",
    "        try:\n",
    "            if df is None:\n",
    "                raise ValueError(f\"DataFrame '{name}' is empty or not loaded.\")\n",
    "            \n",
    "            print_green(f\"{name.capitalize()} DataFrame:\")\n",
    "            df.show(5, truncate=False)\n",
    "            logger.info(f\"Displayed first 5 records for {name.capitalize()} DataFrame.\")\n",
    "        except ValueError as ve:\n",
    "            logger.error(ve)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error displaying DataFrame {name}: {e}\")\n",
    "\n",
    "def validate_data(dfs: dict, validations: list):\n",
    "    \"\"\"\n",
    "    Validate data between DataFrames based on the provided validation rules, with error handling.\n",
    "    \"\"\"\n",
    "    for df1_name, df2_name, id_name in validations:\n",
    "        try:\n",
    "            print_green(f\"Verifying {id_name} matches between {df1_name}.csv and {df2_name}.csv...\")\n",
    "            logger.info(f\"Starting validation of {id_name} between {df1_name}.csv and {df2_name}.csv.\")\n",
    "\n",
    "            # Ensure DataFrames are loaded\n",
    "            if df1_name not in dfs or df2_name not in dfs:\n",
    "                raise ValueError(f\"One of the DataFrames '{df1_name}' or '{df2_name}' is missing.\")\n",
    "\n",
    "            validate_ids(dfs[df1_name], dfs[df2_name], id_name, id_name, id_name)\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            logger.error(ve)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error during data validation: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Load data from CSV files into DataFrames\n",
    "    try:\n",
    "        customers_file_path = \"Dataset/customers.csv\"\n",
    "        products_file_path = \"Dataset/products.csv\"\n",
    "        transactions_file_path = \"Dataset/transactions.csv\"\n",
    "        interactions_file_path = \"Dataset/interactions.csv\"\n",
    "        sales_team_file_path = \"Dataset/sales_team.csv\"\n",
    "\n",
    "        data_files = {\n",
    "            \"customers\": customers_file_path,\n",
    "            \"products\": products_file_path,\n",
    "            \"transactions\": transactions_file_path,\n",
    "            \"interactions\": interactions_file_path,\n",
    "            \"sales_team\": sales_team_file_path\n",
    "        }\n",
    "\n",
    "        # Load DataFrames\n",
    "        dfs = load_data_files(data_files)\n",
    "\n",
    "        # Display initial records for each DataFrame\n",
    "        display_dataframes(dfs)\n",
    "\n",
    "        # Verify Data Accuracy\n",
    "        validations = [\n",
    "            (\"transactions\", \"customers\", \"Customer_ID\"),\n",
    "            (\"interactions\", \"customers\", \"Customer_ID\"),\n",
    "            (\"transactions\", \"products\", \"Product_ID\"),\n",
    "            (\"transactions\", \"sales_team\", \"Sales_Rep_ID\")\n",
    "        ]\n",
    "\n",
    "        validate_data(dfs, validations)\n",
    "\n",
    "        logger.info(\"Data validation completed successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in main execution: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
