{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/17 05:17:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/17 05:17:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/09/17 05:17:25 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/09/17 05:17:25 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/09/17 05:17:25 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/09/17 05:17:25 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "%run /spark-data/CRM/utilities/common_utility.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/17 05:17:27 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = initialize_spark_session(\"Customers Cleaning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:27,150 - logger - INFO - \u001b[92mLogger initialized with dynamic path!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "log_file_path = 'logs/customer_cleaning.log'\n",
    "logger = initialize_logger(log_file_path)\n",
    "\n",
    "logger.info(\"Logger initialized with dynamic path!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:31,107 - logger - INFO - \u001b[92mDisplayed first 5 records of Spark DataFrame.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------+----------------------+-------------+----------------+\n",
      "|Customer_ID                         |Name             |Email                 |Phone        |Country         |\n",
      "+------------------------------------+-----------------+----------------------+-------------+----------------+\n",
      "|a85e6a90-78d5-490c-a53f-c58b2e57c59b|Shannon Deleon   |NULL                  |5878628895   |Japan           |\n",
      "|babec972-ffb3-4c56-99c3-e8e3855adf0f|Christina Sanchez|craigprice@example.org|4832368495   |Haiti           |\n",
      "|d74c33bd-69d9-4718-9e00-d1895a41ddac|Thomas Brown     |vjohnson@example.org  |(276)903-7065|Pakistan        |\n",
      "|ff05ceba-f459-4714-a252-e03198d9934c|Lindsey Bradford |kathryn50@example.net |NULL         |Marshall Islands|\n",
      "|f20755f6-8481-4904-afe6-504451ceded5|John Boyer       |jennifer15@example.org|(749)644-5721|New Caledonia   |\n",
      "+------------------------------------+-----------------+----------------------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "customers_file_path = \"/spark-data/CRM/Dataset/customers.csv\"\n",
    "customers_df = load_data_files(customers_file_path)\n",
    "display_dataframes(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:31,119 - logger - INFO - \u001b[92mStep 1: Counting missing values in each column before filling them...\u001b[0m\n",
      "2024-09-17 05:17:31,833 - logger - INFO - \u001b[92mStep 2: Checking for duplicates in each column before dropping them...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----+-----+-------+\n",
      "|Customer_ID|Name|Email|Phone|Country|\n",
      "+-----------+----+-----+-----+-------+\n",
      "|          0|   0|   52|   52|      0|\n",
      "+-----------+----+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:34,839 - logger - INFO - \u001b[92mStep 3: Formatting and cleaning phone numbers...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|     Column|Duplicate_Count|\n",
      "+-----------+---------------+\n",
      "|Customer_ID|             25|\n",
      "|       Name|             26|\n",
      "|      Email|             22|\n",
      "|      Phone|             23|\n",
      "|    Country|            157|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:35,213 - logger - INFO - \u001b[92mCompleted.\u001b[0m\n",
      "2024-09-17 05:17:35,215 - logger - INFO - \u001b[92mStep 4: Checking and removing duplicate records based on 'Customer_ID'...\u001b[0m\n",
      "2024-09-17 05:17:35,837 - logger - INFO - \u001b[92mNumber of duplicate records before dropping: 25\u001b[0m\n",
      "2024-09-17 05:17:36,181 - logger - INFO - \u001b[92mNumber of duplicate records after dropping: 0\u001b[0m\n",
      "2024-09-17 05:17:36,185 - logger - INFO - \u001b[92mStep 5: Formatting and cleaning Email...\u001b[0m\n",
      "2024-09-17 05:17:37,308 - logger - INFO - \u001b[92mAll non-null emails are valid.\u001b[0m\n",
      "2024-09-17 05:17:37,310 - logger - INFO - \u001b[92mCompleted.\u001b[0m\n",
      "2024-09-17 05:17:37,311 - logger - INFO - \u001b[92mStep 6: Filling missing values in 'Email' and 'Phone' columns...\u001b[0m\n",
      "2024-09-17 05:17:37,757 - logger - INFO - \u001b[92mStep 7: Capitalizing the first letter of each word in the 'Name' and 'Country' columns...\u001b[0m\n",
      "2024-09-17 05:17:37,781 - logger - INFO - \u001b[92mCompleted.\u001b[0m\n",
      "2024-09-17 05:17:37,784 - logger - INFO - \u001b[92mStep 8: Counting missing values in each column after filling them...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------+----------------------+---------------+-----------+\n",
      "|Customer_ID                         |Name             |Email                 |Phone          |Country    |\n",
      "+------------------------------------+-----------------+----------------------+---------------+-----------+\n",
      "|003ca69a-991c-4c11-899a-51bb7365499d|Erica Diaz       |hurleyanna@example.com|+964-8545044941|Iraq       |\n",
      "|006af455-013b-4c09-a6df-15ca3d41010f|Jason Jackson    |dylanduran@example.com|+63-2484285464 |Philippines|\n",
      "|00fc38f7-b5c7-465c-839b-a55185f2635f|Heather Schneider|larajohn@example.org  |+264-7935879728|Namibia    |\n",
      "|015cc4e1-5cf8-441c-80ad-ca3536c53e9a|Matthew Wilson   |timothyho@example.org |+357-8883554148|Cyprus     |\n",
      "|01d13428-d511-4c3d-90c7-b5624931ff48|Robert Contreras |lydia12@example.com   |unknown        |Swaziland  |\n",
      "+------------------------------------+-----------------+----------------------+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:38,119 - logger - INFO - \u001b[92mStep 9: Checking for duplicates in each column after dropping them...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----+-----+-------+\n",
      "|Customer_ID|Name|Email|Phone|Country|\n",
      "+-----------+----+-----+-----+-------+\n",
      "|          0|   0|    0|    0|      0|\n",
      "+-----------+----+-----+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 05:17:40,112 - logger - INFO - \u001b[92mStep 10: Exporting the cleaned data to 'cleaned_customers.csv'...\u001b[0m\n",
      "2024-09-17 05:17:40,253 - logger - INFO - \u001b[92mNumber of records after cleaning: 500\u001b[0m\n",
      "2024-09-17 05:17:40,255 - logger - INFO - \u001b[92mData cleaning and export completed successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|     Column|Duplicate_Count|\n",
      "+-----------+---------------+\n",
      "|Customer_ID|              0|\n",
      "|       Name|              1|\n",
      "|      Email|              1|\n",
      "|      Phone|              1|\n",
      "|    Country|            151|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Count missing (null) values for each column before filling them\n",
    "logger.info(\"Step 1: Counting missing values in each column before filling them...\")\n",
    "missing_values_before = count_missing_values(customers_df)\n",
    "missing_values_before.show()\n",
    "\n",
    "# Step 2: Count duplicates before dropping them\n",
    "logger.info(\"Step 2: Checking for duplicates in each column before dropping them...\")\n",
    "duplicate_count = count_duplicates_per_column(customers_df)\n",
    "duplicate_count.show()\n",
    "\n",
    "# Step 3: Format and clean phone numbers\n",
    "logger.info(\"Step 3: Formatting and cleaning phone numbers...\")\n",
    "countries = \"/spark-data/CRM/Dataset/countries.csv\"\n",
    "cleaned_customers_df = process_phone_numbers(customers_df,countries)\n",
    "logger.info(\"Completed.\")\n",
    "\n",
    "# Step 4: Drop duplicates based on 'Customer_ID' if any are found\n",
    "logger.info(\"Step 4: Checking and removing duplicate records based on 'Customer_ID'...\")\n",
    "cleaned_customers_df = drop_duplicates(cleaned_customers_df, \"Customer_ID\")\n",
    "\n",
    "# Step 5: Format and clean Email\n",
    "logger.info(\"Step 5: Formatting and cleaning Email...\")\n",
    "cleaned_customers_df = validate_emails(cleaned_customers_df, \"Email\")\n",
    "logger.info(\"Completed.\")\n",
    "\n",
    "# Step 5: Fill missing values in 'Email' and 'Phone' columns\n",
    "logger.info(\"Step 6: Filling missing values in 'Email' and 'Phone' columns...\")\n",
    "cleaned_customers_df = fill_missing_values(cleaned_customers_df, {'Email': 'unknown', 'Phone': 'unknown'})\n",
    "cleaned_customers_df.show(5, truncate=False)\n",
    "\n",
    "# Step 6: Capitalize the first letter of the first and last names in the 'Name' and 'Country' columns\n",
    "logger.info(\"Step 7: Capitalizing the first letter of each word in the 'Name' and 'Country' columns...\")\n",
    "cleaned_customers_df = capitalize_columns(cleaned_customers_df, [\"Name\", \"Country\"])\n",
    "logger.info(\"Completed.\")\n",
    "\n",
    "# Step 7: Cross-validation - Count missing values again after filling them\n",
    "logger.info(\"Step 8: Counting missing values in each column after filling them...\")\n",
    "missing_values_after = count_missing_values(cleaned_customers_df)\n",
    "missing_values_after.show()\n",
    "\n",
    "# Step 8: Count duplicates after dropping them\n",
    "logger.info(\"Step 9: Checking for duplicates in each column after dropping them...\")\n",
    "duplicate_count_after = count_duplicates_per_column(cleaned_customers_df)\n",
    "duplicate_count_after.show()\n",
    "\n",
    "# Step 9: Export the cleaned data to a CSV file\n",
    "logger.info(\"Step 10: Exporting the cleaned data to 'cleaned_customers.csv'...\")\n",
    "# save_df_to_csv(cleaned_customers_df, \"Cleaned_data/cleaned_customers.csv\")\n",
    "\n",
    "# Display the count of records after phone number processing\n",
    "record_count_after_cleaning = cleaned_customers_df.count()\n",
    "logger.info(f\"Number of records after cleaning: {record_count_after_cleaning}\")\n",
    "\n",
    "logger.info(\"Data cleaning and export completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
